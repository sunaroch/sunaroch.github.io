<!doctype html>
<html lang="en">
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face to Video</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
        }
        img {
            max-width: 100%;
            height: auto;
        }
    </style>
</head>
  <body>
    <h2>Face to Video - The Visualization and Sonification of Connection</h2>
    <video width="400" height="360" controls>
        <source src="videoproject3.mov" type="video/quicktime">
        Your browser does not support the video tag.
    </video>

    <p>In this project, I experimented with MaxMSP in order to illustrate feelings of connection between two people. Features include: increased saturation
    upon eye contact, sounds of the ocean become louder when eyes are closed, movement of the mouth affects the frequency of each sine 
    wave, winking leads to different hues, and blinking makes the video more pixelated. </p>
    <p>Not only is the video exciting to look at, it becomes more exciting when the user finds ways to affect it. The project is designed
    for experimentation, for interactivity between users themselves.</p>

    <h3>The Max Patch:</h3>
    <figure>
        <img src="maxpatch.png" width="400" height="300">
    </figure>
    <p>I used two cameras and two Max patches to complete this project. The max patches record the movements of each person, and the second
    patch sends messages of these values over to the first patch (using "send" and "receieve" objects), where I used Vizzie in order to add effects to a video that I provided. Above is a 
    screenshot of the first Max patch, where we can see how everything is being affected. I scaled these values according to what was most 
    visually accurate to how I feel when I am connecting with someone.</p>
    <p>I am planning to build on this project on a bigger scale, perhaps with a performance or exhibition element.</p>

  </body>
</html>  

